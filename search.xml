<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>NLP模型:Transformer:Self-Attention</title>
      <link href="/2020/04/10/nlp-mo-xing-transformer-self-attention/"/>
      <url>/2020/04/10/nlp-mo-xing-transformer-self-attention/</url>
      
        <content type="html"><![CDATA[<meta name="referrer" content="no-referrer">以下参考：https://www.jianshu.com/p/d2ae158fc9e5<p>**attention：**输入和输出进行比较，不同的输出对不同输入的关注不同。假设输出$y_1$更关注输入$x_1$，$y_2$更关注$x_2$，那么在句子翻译中，语言$x_1x_2 \cdots x_n$翻译成$y_1y_2 \cdots y_n$，那么很可能认为单词$x_1$翻译成$y_1$，$x_2$翻译成$y_2$。能够使模型捕捉有用信息。</p><p>**self-attention：**输入和输入自己进行比较（计算相似度），将输入的与上下文无关的词向量更新成上下文有关的词向量。解决了RNN等的短时记忆问题（即某个输入的词向量只与前几个输入有关）。</p><a id="more"></a><h2 id="self-attention-计算过程">self-attention 计算过程</h2><p><img src="https://upload-images.jianshu.io/upload_images/18879971-c679a5c9e81e9e0e.png?imageMogr2/auto-orient/strip%7CimageView2/2/h/240" alt="self-attention计算过程1：嵌入词向量，再由词向量依次线性变换出queries keys values"></p><p>Thinking 和 Machines是同一组输入（同一句话）中的某两个输入（某两个单词），$x$是上下文无关的词向量</p><p>####1.  根据原词向量依次计算queries，Keys，Values</p><p>$$Queries = X*W^Q$$</p><p>$$Keys = Queries*W^K$$</p><p>$$Values = Keys*W^V$$</p><p>其中，$W^Q，W^K，W^V$是待训练的参数</p><p><img src="https://upload-images.jianshu.io/upload_images/18879971-8f31443c573844bf.png?imageMogr2/auto-orient/strip%7CimageView2/2/h/340" alt="self-attention计算过程2"></p><p>####2.  计算scores</p><p>$$<br>scores=\frac{q_i* keys}{\sqrt{d_{k}}}<br>$$<br>每个$q_i$都算出n个score，即(1,n)的scores向量<br>其中，$d_k$是超参数（这里取64），为了让后面的计算中具有稳定的梯度</p><p>####3.  计算（能句子中的长依赖关系）的新向量</p><p>$$<br>z_i=softmax（scores）*v<br>$$</p><p>对于某个词向量，$softmax（scores）$即为所有词向量对该词向量的权重，将这些权重分别乘以各向量得到新向量。运算为$(1，n)*(n,1)$</p><p>那么最后能生成输入句子中单词与单词直接的权重矩阵，即注意力矩阵<br><img src="https://upload-images.jianshu.io/upload_images/18879971-8009c95c8f726cd9.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/h/200" alt="注意力矩阵"></p><h2 id="self-attention的优点">self-attention的优点</h2><ol><li>传统的RNN，LSTM网络，需要按顺序进行序列计算，所以距离越远，关系越难捕捉。如果面对长句子，这种距离较远的依赖关系相比之下很难捕获到。而self-attention是针对句子中所有词两两计算，不存在距离长短的问题</li><li>相比循环网络，self-attention能并行计算</li></ol><p>以下参考：<a href="https://mp.weixin.qq.com/s/RLxWevVWHXgX-UcoxDS70w" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/RLxWevVWHXgX-UcoxDS70w</a></p><h2 id="transformer总体框架">transformer总体框架</h2><p><img src="https://upload-images.jianshu.io/upload_images/18879971-6367eb5c9bba5055.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/h/80" alt="输入经过transoformer得到输出"></p><p>transfromer内部结构总体框架</p><p><img src="https://upload-images.jianshu.io/upload_images/18879971-e93682a7195fe536.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/h/360" alt="transformer模型框架"></p><p>上述框架可抽象成Encoders和Decoders</p><p><img src="https://upload-images.jianshu.io/upload_images/18879971-5fd669cd0989d166.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/h/240" alt="transformer也是一个Encoder-Decoder模型"></p><p>Encoders包含6个Encoder，Decoders包含6个Decoder<br>最后一个Encoder与6个Decoder建立连接，连接的意思是某种运算，例如RNN是使用中间语义$c$作为中间连接</p><p><img src="https://upload-images.jianshu.io/upload_images/18879971-4881c62c0c112c00.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/h/240/" alt></p><p>以最后的那个Encoder和其中一个Decoder的连接为例，继续探究Encoder和Decoder的内部<br>Encoder和Decoder都有Self-Attention和Feed Forward层，Decoder还有一个 Encoder-Decoder Attention层，注意，Decoder中的注意力层其实是masked self-attention</p><p><img src="https://upload-images.jianshu.io/upload_images/18879971-676c87728e39a0e1.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/h/140" alt="Encoder和Decoder的内部结构"></p><h2 id="以下探究transformer模型的每个层">以下探究transformer模型的每个层</h2><h2 id="1-transformer的Self-Attention层：Scaled-Dot-Product-Attention">1.transformer的Self-Attention层：Scaled Dot-Product Attention</h2><p>同样，计算Self-Attention需要三个参数Q，K，V去计算注意力机制矩阵，这里重新定义了计算方式，如下</p><p><img src="https://upload-images.jianshu.io/upload_images/18879971-964dcad7f87ddc35.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/h/240" alt="根据Q，K，V计算注意力机制矩阵"></p><p>self-attention得到的注意力矩阵同上<br>masked self-attention得到的注意力矩阵与上面有点不同，这里的masked就是要在做翻译的时候，不给模型看到未来的信息。</p><p><img src="https://upload-images.jianshu.io/upload_images/18879971-08d4a0c9cec1c28c.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/h/240" alt="masked注意力矩阵"></p><h2 id="3-Multi-Head-Attention">3. Multi-Head Attention</h2><p>Multi-Head Attention就是把Scaled Dot-Product Attention的过程做h次，然后把输出$z$合起来。它的结构图如下</p><p><img src="https://upload-images.jianshu.io/upload_images/18879971-8de30254aa2155b7.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/h/340" alt="h次Scaled Dot-Product Attention"></p><p><img src="https://upload-images.jianshu.io/upload_images/18879971-04691dc7c88193a5.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/h/240" alt="重复率8次，生成8个z"></p><p>输出$z$合起来后乘以一个参数$w^o$矩阵联合训练</p><p><img src="https://upload-images.jianshu.io/upload_images/18879971-909bf4759ba3d0c6.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/h/240" alt="8个z合起来"></p><h2 id="4-Position-Embedding">4. Position Embedding</h2><p>因为注意力模型不像RNN那样无视了各输入之间的距离，因此是无法捕捉到序列顺序信息的，例如将K、V按行进行打乱，Attention之后的结果是一样的。为了保留序列信息，需要在embeddings得到的词向量上在加上一个包含序列信息的向量，即Position Embedding得到的向量。</p><p><img src="https://upload-images.jianshu.io/upload_images/18879971-ad765d2d2bdbaad5.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/h/240" alt="Position Embedding"></p><p>Position Embedding计算方法：</p><p>Position Embedding的第偶数个元素<br>$$<br>P E_{(\text {pos}, 2 i)}=\sin \left(\text {pos} / 10000^{2 i / d_{\text {model}}}\right)<br>$$</p><p>Position Embedding的第奇数个元素<br>$$<br>P E_{(\text {pos}, 2 i+1)}=\cos \left(\text {pos} / 10000^{2 i / d_{\text {model}}}\right)<br>$$</p><h2 id="5-Position-wise-Feed-forward-Networks">5. Position-wise Feed-forward Networks</h2><p>Relu激活函数和两次线性变换<br>$$<br>F F N(x)=\max \left(0, x W_{1}+b_{1}\right) W_{2}+b_{2}<br>$$</p><h2 id="最后，总体框架采用残差连接方式对各层进行连接，参考ResNet">最后，总体框架采用残差连接方式对各层进行连接，参考ResNet</h2>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NLP模型:Attetion注意力机制</title>
      <link href="/2020/04/10/nlp-mo-xing-attetion-zhu-yi-li-ji-zhi/"/>
      <url>/2020/04/10/nlp-mo-xing-attetion-zhu-yi-li-ji-zhi/</url>
      
        <content type="html"><![CDATA[<meta name="referrer" content="no-referrer">参考 https://www.jianshu.com/p/e14c6a722381<h2 id="1-Encoder-Decoder-模型">1.Encoder-Decoder 模型</h2><p><img src="https://upload-images.jianshu.io/upload_images/18879971-fdd8ec909b5f36a3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Encoder-Decoder 模型"></p><p>其中，$x_1x_2 \cdots x_4 $为输入（假设为待翻译的句子），$y_1y_2 \cdots y_4 $为输出（假设为目标翻译句子），$c$为中间语义变量</p><p>$$c=g(x_1,x_2 \cdots x_4)$$</p><p>$$<br>y_1 = f( c )<br>$$</p><p>$$<br>y_2 = f(c,y_1)<br>$$</p><p>$$<br>y_i = f(c,y_1,y_2 \cdots y_{i-1})<br>$$</p><p>$g$和$f$为任意非线性变换，如RNN，CNN</p><a id="more"></a><h2 id="2-Attention模型">2.Attention模型</h2><p>Attetion 在 Encoder-Decoder 基础上，使输出$y_i$不再共享同一个$c$，每个$y_i$对应一个$c_i$。注意力的意思就是对于一个输出$y_1$，可能更关注$x_1$而比较少关注其他输入，即$y_1$主要被$x_1$影响，计算$c_1$时，$x_1$的权重也更大</p><p><img src="https://upload-images.jianshu.io/upload_images/18879971-59fe6726a39279bc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="引入注意力机制后的Attetion模型.png"></p><p>$$<br>c_i = g(\omega_1 * x_1 +\omega_2 * x_2 + \cdots + \omega_i * x_i)<br>$$</p><p>$$<br>y_1 = f(c_1)<br>$$</p><p>$$<br>y_2 = f(c_2,y_1)<br>$$</p><p>$$<br>y_i = f(c_i,y_1,y_2 \cdots y_{i-1})<br>$$</p><p>下面讨论$\omega$的值如何计算</p><p><img src="https://upload-images.jianshu.io/upload_images/18879971-50141795ad8557c0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="假设Encoder和Decoder都是RNN模型"></p><p>如图，$h_i$为输入的隐藏层，$H_i$为输出的隐藏层，都可以在计算$y_i$前算出</p><p>向量$\omega$由$h_i$和$H_i$经某种变换$F$并经过softmax层得出：</p><p><img src="https://upload-images.jianshu.io/upload_images/18879971-94c3917db8015bb5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="计算w的过程"></p><h2 id="3-对Attetnion模型进行更一般化的表示">3. 对Attetnion模型进行更一般化的表示</h2><p><img src="https://upload-images.jianshu.io/upload_images/18879971-2eebbf5663a1afc9.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="attention模型权重的一般化计算方法"></p><p>如图，Query相当于上面提到的RNN的Encoder中的隐藏层$h$，Key相当于RNN的Encoder中的隐藏层$H$，a相当于$\omega$，Value相当于输入$x$，Attention Value相当于中间语义$c$</p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NLP中文分词:二、统计分词</title>
      <link href="/2020/04/10/nlp-zhong-wen-fen-ci-er-tong-ji-fen-ci/"/>
      <url>/2020/04/10/nlp-zhong-wen-fen-ci-er-tong-ji-fen-ci/</url>
      
        <content type="html"><![CDATA[<p><strong>统计分词</strong>：为长度为$m$ 的字符串确定其概率分布 $p(\omega_1,\omega_2,\cdots,\omega_m)$ ，其中$\omega_1$到 $\omega_m$ 依次表示文本中的各个词语,一般使用二元概率模型:<br>$$<br>P\left(\omega_{i} | \omega_{1}, \omega_{2}, \cdots, \omega_{i-1}\right) \approx<br>P\left(\omega_{i} | \omega_{i-1}\right)<br>$$</p><h2 id="1-HMM隐含马尔科夫模型">1. HMM隐含马尔科夫模型</h2><h3 id="引言">引言</h3><p>将分词作为字在字串中的序列标注任务 。对每个字标注其词位（该字在词中的位置），现规定只有四种词位：B (词首)、 M( 词中)、 E (词尾)，S(单独成词 )</p><p>对每个字的标签记为$o_{i}$,每个字记为$\omega_{i}$则目标函数：</p><p>$$<br>\max =\max P\left(o_{1} o_{2} \cdots o_{n} | \omega_{1} \omega_{2} \cdots \omega_{n}\right)<br>$$</p><p>上面式子太难算，独立性假设：</p><p>$$<br>P\left(o_{1} o_{2} \cdots o_{n} | \omega_{1} \omega_{2} \cdots \omega_{n}\right)=P\left(o_{1} | \omega_{1}\right) P\left(o_{2} | \omega_{2}\right) \cdots P\left(o_{n} | \omega_{n}\right)<br>$$</p><p>这样的假设又会忽视上下文关系，可能会出现B（词首）B（词首）的问题，而两个词首不可能连续出现。</p><a id="more"></a><h3 id="HMM">HMM</h3><p>HMM是解决此问题的一种办法。<br>根据贝叶斯公式：</p><p>$$<br>P(o | \omega)=\frac{P(o, \omega)}{P(\omega)}=\frac{P(\omega | o) P(o)}{P(\omega)}<br>$$</p><p>$P(\omega)$ 为常数,所以目标函数：</p><p>$$\max P(o | \omega) \Leftrightarrow \max P(\omega | o) P(o)$$</p><p>针对 $P(\omega | o) P(o)$作马尔可夫假设，得到 :</p><p>$$<br>P(\omega | o)=P\left(\omega_{1} | o_{1}\right) P\left(\omega_{2} | o_{2}\right) \cdots P\left(\omega_{n} | o_{n}\right)<br>$$</p><p>又根据联合概率链式法则并进行齐次马尔可夫假设：</p><p><strong>齐次马尔可夫假设</strong>，下一个状态只与上一个状态有关，即下一个词出现的概率只与上一个词有关，也是二元模型的假设前提</p><p>$$<br>P(o)=P\left(o_{1}\right) P\left(o_{2} | o_{1}\right) P\left(o_{3} | o_{2}\right) \cdots P\left(o_{n} | o_{n-1}\right)<br>$$</p><p>综上：</p><p>$$\max P(\omega | o) P(o) =  \max<br>P\left(\omega_{1} | o_{1}\right) P\left(o_{2} | o_{1}\right) P\left(\omega_{2} | o_{2}\right) P\left(o_{3} | o_{2}\right) \cdots P\left(o_{n} | O_{n-1}\right) \mathrm{P}\left(\omega_{n} | O_{n}\right) $$</p><p>$P\left(\omega_{k} | o_{k}\right)$ 称为发射概率 , $P\left(o_{k} | o_{k-1}\right)$ 称为转移概率,通过设置某些$P\left(o_{k} | o_{k-1}\right)=0<br>$，可以排除类似 BBB 、 EM 等不合理的组合。求解$\max P(\omega | o) P(o)$的方法参见Veterbi 动态规划算法</p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NLP中文分词:一、规则分词之最大匹配法</title>
      <link href="/2020/04/10/nlp-zhong-wen-fen-ci-yi-gui-ze-fen-ci-zhi-zui-da-pi-pei-fa/"/>
      <url>/2020/04/10/nlp-zhong-wen-fen-ci-yi-gui-ze-fen-ci-zhi-zui-da-pi-pei-fa/</url>
      
        <content type="html"><![CDATA[<p>基于规则的分词主要是通过维护词典（词典尽可能含有中文的所有词语）， 在切分语句时，将语句的每个字符串与词表中的词进行逐一匹配找到则切分，否则不予切分 。<br>主要有正向<strong>最大匹配法</strong>、<strong>逆向最大匹配法</strong>以及<strong>双向最大匹配法</strong>三种方法 。</p><h2 id="1-正向最大匹配法">1. 正向最大匹配法</h2><p>算法：</p><ol><li>从左向右取待切分汉语句的前m 个字符（m为词典里最长的词字符数）；</li><li>若这m个字符属于词典里面的词，则称匹配成功，然后将这m个字符切分出来，剩下的词语作为新的待切分汉语句；</li><li>若这m个字符不属于词典里面的词，则去除这m个字符的<strong>最后一个字符</strong>，剩余的m-1个字符继续匹配，直到匹配或剩下一个字符为止；</li><li>重复以上步骤，直到汉语句切完；</li></ol><a id="more"></a><h2 id="2-逆向最大匹配法">2. 逆向最大匹配法</h2><p>逆向最大匹配法与正向最大匹配法的区别在于步骤3：若这m个字符不属于词典里面的词，则去除这m个字符的第一个字符</p><h2 id="3-双向最大匹配法">3. 双向最大匹配法</h2><p>同时运用正向最大匹配法和逆向最大匹配法，比较两者结果，取分词数少的结果作为最终结果</p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch训练保存检验模型基本流程</title>
      <link href="/2020/04/10/pytorch-xun-lian-bao-cun-jian-yan-mo-xing-ji-ben-liu-cheng/"/>
      <url>/2020/04/10/pytorch-xun-lian-bao-cun-jian-yan-mo-xing-ji-ben-liu-cheng/</url>
      
        <content type="html"><![CDATA[<blockquote><p>参考：<br><a href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py" target="_blank" rel="noopener">https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py</a></p></blockquote><h2 id="Step1准备数据输入">Step1准备数据输入</h2><p>按需制作训练集</p><a id="more"></a><h2 id="Step2-设计神经网络">Step2 设计神经网络</h2><p>注意forward()函数是override method，名字不能改</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.pool(F.relu(self.conv1(x)))</span><br><span class="line">        x = self.pool(F.relu(self.conv2(x)))</span><br><span class="line">        x = x.view(<span class="number">-1</span>, <span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>)</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = Net()</span><br></pre></td></tr></table></figure><p>##Step3 定义损失函数和优化方法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure><p>##Step4 训练网络</p><p>####4.1 循环更新参数</p><ul><li>for epoch in range(times):<ul><li>参数的梯度置零</li><li>前向传播获取神经网络的输出</li><li>比较输出与标签的差距并计算损失</li><li>损失反向传播</li><li>优化器更新参数</li><li>累计损失</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">2</span>):  <span class="comment"># loop over the dataset multiple times</span></span><br><span class="line"></span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> enumerate(trainloader, <span class="number">0</span>):</span><br><span class="line">        <span class="comment"># get the inputs; data is a list of [inputs, labels]</span></span><br><span class="line">        inputs, labels = data</span><br><span class="line"></span><br><span class="line">        <span class="comment"># zero the parameter gradients</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># forward + backward + optimize</span></span><br><span class="line">        outputs = net(inputs)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        running_loss += loss.item()</span><br></pre></td></tr></table></figure><p>##Step4 保存训练结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.save(net.state_dict(), PATH)</span><br></pre></td></tr></table></figure><h2 id="Step5-恢复并评估模型">Step5 恢复并评估模型</h2><p>####5.1恢复模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net = Net()</span><br><span class="line">net.load_state_dict(torch.load(PATH))</span><br></pre></td></tr></table></figure><p>####5.2 测试集前向传播得到输出</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">  outputs = net(images)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VNC访问mate或gnome桌面的服务端配置</title>
      <link href="/2020/04/10/vnc-fang-wen-mate-huo-gnome-zhuo-mian-de-fu-wu-duan-pei-zhi/"/>
      <url>/2020/04/10/vnc-fang-wen-mate-huo-gnome-zhuo-mian-de-fu-wu-duan-pei-zhi/</url>
      
        <content type="html"><![CDATA[<h2 id="VNCserver">VNCserver</h2><ul><li><h4 id="安装vnc4server">安装vnc4server</h4></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install vnc4server</span><br></pre></td></tr></table></figure><ul><li><h4 id="启动vncserver-指定为端口1为例">启动vncserver(指定为端口1为例)</h4></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vncserver :1</span><br></pre></td></tr></table></figure><p>第一次启动vncserver会自动在<code>~/.vnc/</code>目录下生成<code>~/.vnc/xstartup</code>等文件</p><ul><li><h4 id="然后关闭vncserver">然后关闭vncserver</h4></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vncserver -kill :1</span><br></pre></td></tr></table></figure><a id="more"></a><ul><li><h4 id="按附录代码修改xstartup文件">按附录代码修改xstartup文件</h4><ul><li>方法一</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.vnc/xstartup</span><br></pre></td></tr></table></figure><ul><li>方法二</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rm ~/.vnc/xstartup # 删除掉xstartup文件</span><br><span class="line">vi ~/.vnc/xstartup # 创建新的xstartup文件直接粘贴附录代码</span><br><span class="line">chmod 777 ~/.vnc/xstartup # 授权使其可执行</span><br></pre></td></tr></table></figure></li></ul><h2 id="附录">附录</h2><h4 id="gnome桌面">gnome桌面</h4><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/<span class="keyword">sh</span></span><br><span class="line"></span><br><span class="line"># Uncomment the following two lines <span class="keyword">for</span> <span class="keyword">normal</span> desktop:</span><br><span class="line"># unset SESSION_MANAGER</span><br><span class="line"># exec /etc/X11/xinit/xinitrc</span><br><span class="line">  </span><br><span class="line">[ -<span class="keyword">x</span> /etc/vnc/xstartup ] &amp;&amp; exec /etc/vnc/xstartup</span><br><span class="line">[ -r $HOME/.Xresources ] &amp;&amp; xrdb $HOME/.Xresources</span><br><span class="line">xsetroot -solid grey </span><br><span class="line">vncconfig -iconic &amp;</span><br><span class="line"><span class="keyword">x</span>-terminal-emulator -geometry <span class="number">80</span>x24+<span class="number">10</span>+<span class="number">10</span> -<span class="keyword">ls</span> -title <span class="string">"$VNCDESKTOP Desktop"</span> &amp;</span><br><span class="line"><span class="keyword">x</span>-window-manager &amp;</span><br><span class="line"></span><br><span class="line">gnome-panel &amp;</span><br><span class="line">gnome-settings-daemon &amp;</span><br><span class="line">metacity &amp;</span><br></pre></td></tr></table></figure><h4 id="mate桌面">mate桌面</h4><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/<span class="keyword">sh</span></span><br><span class="line"># Uncomment the following two lines <span class="keyword">for</span> <span class="keyword">normal</span> desktop:</span><br><span class="line"># unset SESSION_MANAGER</span><br><span class="line"># exec /etc/X11/xinit/xinitrc</span><br><span class="line"></span><br><span class="line">#export XKL_XMODMAP_DISABLE=<span class="number">1</span></span><br><span class="line">unset SESSION_MANAGER</span><br><span class="line">unset DBUS_SESSION_BUS_ADDRESS</span><br><span class="line">[ -<span class="keyword">x</span> /etc/vnc/xstartup ] &amp;&amp; exec /etc/vnc/xstartup</span><br><span class="line">[ -r $HOME/.Xresources ] &amp;&amp; xrdb $HOME/.Xresources</span><br><span class="line">xsetroot -solid grey</span><br><span class="line">vncconfig -iconic &amp;</span><br><span class="line"># <span class="keyword">x</span>-terminal-emulator -geometry <span class="number">80</span>x24+<span class="number">10</span>+<span class="number">10</span> -<span class="keyword">ls</span> -title <span class="string">"$VNCDESKTOP Desktop"</span> &amp;</span><br><span class="line">mate-session &amp;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tensorflow训练保存检验模型基本流程</title>
      <link href="/2020/04/10/tensorflow-xun-lian-bao-cun-jian-yan-mo-xing-ji-ben-liu-cheng/"/>
      <url>/2020/04/10/tensorflow-xun-lian-bao-cun-jian-yan-mo-xing-ji-ben-liu-cheng/</url>
      
        <content type="html"><![CDATA[<p>参考：<br>TensorFlow运作方式入门http://www.tensorfly.cn/tfdoc/tutorials/mnist_tf.html</p><p>注意以下代码仅为示例</p><h2 id="Step1准备数据输入">Step1准备数据输入</h2><p>按需制作训练集</p><h2 id="Step2-构造图表-Build-the-Graph">Step2 构造图表(Build the Graph)</h2><p>####2.1定义占位符</p><p>在创建session的时候数据才真正流入神经网络</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">images_placeholder = tf.placeholder(tf.float32, shape=(batch_size,</span><br><span class="line">                                                       IMAGE_PIXELS))</span><br><span class="line">labels_placeholder = tf.placeholder(tf.int32, shape=(batch_size))</span><br></pre></td></tr></table></figure><a id="more"></a><p>####2.2构造inference()<br>占位符为输入，使数据经过神经网络向前反馈输出预测结果<br>每一层都创建于一个唯一的<a href="http://www.tensorfly.cn/tfdoc/api_docs/python/framework.html#name_scope" target="_blank" rel="noopener"><code>tf.name_scope</code></a>之下，创建于该作用域之下的所有元素都将带有其前缀</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inference</span><span class="params">(images, hidden1_units, hidden2_units)</span>:</span></span><br><span class="line">  <span class="comment"># Hidden 1</span></span><br><span class="line">  <span class="keyword">with</span> tf.name_scope(<span class="string">'hidden1'</span>):</span><br><span class="line">    weights = tf.Variable(</span><br><span class="line">        tf.truncated_normal([IMAGE_PIXELS, hidden1_units],</span><br><span class="line">                            stddev=<span class="number">1.0</span> / math.sqrt(float(IMAGE_PIXELS))),</span><br><span class="line">        name=<span class="string">'weights'</span>)</span><br><span class="line">    biases = tf.Variable(tf.zeros([hidden1_units]),</span><br><span class="line">                         name=<span class="string">'biases'</span>)</span><br><span class="line">    hidden1 = tf.nn.relu(tf.matmul(images, weights) + biases)</span><br><span class="line">  <span class="comment"># Hidden 2</span></span><br><span class="line">  <span class="keyword">with</span> tf.name_scope(<span class="string">'hidden2'</span>):</span><br><span class="line">    weights = tf.Variable(</span><br><span class="line">        tf.truncated_normal([hidden1_units, hidden2_units],</span><br><span class="line">                            stddev=<span class="number">1.0</span> / math.sqrt(float(hidden1_units))),</span><br><span class="line">        name=<span class="string">'weights'</span>)</span><br><span class="line">    biases = tf.Variable(tf.zeros([hidden2_units]),</span><br><span class="line">                         name=<span class="string">'biases'</span>)</span><br><span class="line">    hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases)</span><br><span class="line">  <span class="comment"># Linear</span></span><br><span class="line">  <span class="keyword">with</span> tf.name_scope(<span class="string">'softmax_linear'</span>):</span><br><span class="line">    weights = tf.Variable(</span><br><span class="line">        tf.truncated_normal([hidden2_units, NUM_CLASSES],</span><br><span class="line">                            stddev=<span class="number">1.0</span> / math.sqrt(float(hidden2_units))),</span><br><span class="line">        name=<span class="string">'weights'</span>)</span><br><span class="line">    biases = tf.Variable(tf.zeros([NUM_CLASSES]),</span><br><span class="line">                         name=<span class="string">'biases'</span>)</span><br><span class="line">    logits = tf.matmul(hidden2, weights) + biases</span><br><span class="line">  <span class="keyword">return</span> logits</span><br></pre></td></tr></table></figure><p>####2.3损失(Loss)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits,</span><br><span class="line">                                                        onehot_labels,</span><br><span class="line">                                                        name=<span class="string">'entropy'</span>)</span><br><span class="line">loss = tf.reduce_mean(cross_entropy, name=<span class="string">'entropy_mean'</span>)</span><br></pre></td></tr></table></figure><p>####2.4训练(training)<br>#####2.4.1将损失最小化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate)</span><br><span class="line">train_op = optimizer.minimize(loss, global_step=global_step)</span><br></pre></td></tr></table></figure><p>#####2.4.2生成一个变量用于保存全局训练步骤（global training step）的数值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">global_step = tf.Variable(<span class="number">0</span>, name=<span class="string">'global_step'</span>, trainable=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p>##step3 启动会话并执行图表</p><p>####3.1关联图表构建会话</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">saver = tf.train.Saver() <span class="comment">#保存模型：定义一个saver</span></span><br><span class="line"><span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        init = tf.initialize_all_variables()</span><br><span class="line">        sess.run(init)</span><br></pre></td></tr></table></figure><p>####3.2 feed_dict参数传入sess.run()，真正训练模型，保存模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> xrange(FLAGS.max_steps):</span><br><span class="line">    feed_dict = &#123;</span><br><span class="line">        images_placeholder: images_feed,</span><br><span class="line">        labels_placeholder: labels_feed,</span><br><span class="line">    &#125;</span><br><span class="line">    _, loss_value = sess.run([train_op, loss],</span><br><span class="line">                     feed_dict=feed_dict)</span><br><span class="line">    </span><br><span class="line">    saver.save(sess, FLAGS.train_dir, global_step=step)</span><br><span class="line">    <span class="comment">#保存模型：检查点保存到FLAGS.train_dir,</span></span><br></pre></td></tr></table></figure><h2 id="Step4-恢复并评估模型">Step4 恢复并评估模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    model_dir=tf.train.latest_checkpoint(<span class="string">'ckpt/'</span>)</span><br><span class="line">    saver.restore(sess,model_dir)</span><br><span class="line">    ***=sess.run(***, feed_dict=&#123;))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> tensorflow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tensorflow入门笔记3:placeholder机制和Variable变量</title>
      <link href="/2019/10/06/tensorflow-ru-men-bi-ji-3-placeholder-ji-zhi-he-variable-bian-liang/"/>
      <url>/2019/10/06/tensorflow-ru-men-bi-ji-3-placeholder-ji-zhi-he-variable-bian-liang/</url>
      
        <content type="html"><![CDATA[<h2 id="1-placeholder-机制">1.placeholder 机制</h2><ul><li>placeholder 机制的作用</li></ul><p>网络的输入数据是一个矩阵，我们把多个这样的矩阵数据打包成一个很大的数据集，如果将这个数据集当作变量或常量一下子输入到网络中，那么就需要定义很多的网络输入常量，于是计算图上将会涌现大量的输入节点。这是不利的，这些节点的利用率很低。<br>placehoder 机制被设计用来解决这个问题。编程时只需要将数据通过 placeholder 传入 TensorFlow 计算图即可。</p><ul><li>使用 <code>tf.placeholder()</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">a = tf.placeholder(tf.float32,shape=(<span class="number">2</span>),name=<span class="string">"input"</span>) </span><br><span class="line">b = tf.placeholder(tf.float32,shape=(<span class="number">2</span>),name=<span class="string">"input"</span>)</span><br><span class="line">result = a+b</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess :</span><br><span class="line">  sess.run(result,feed_dict=&#123;a:[<span class="number">1.0</span>,<span class="number">2.0</span>],b:[<span class="number">3.0</span>,<span class="number">4.0</span>]&#125;)</span><br><span class="line">  print(result)</span><br><span class="line">  ＃输出[<span class="number">4.</span>,<span class="number">6.</span>]</span><br></pre></td></tr></table></figure><a id="more"></a><p>在 placeholder 定义时，这个位置上的数据类型<code>dtype</code>是需要指定且不可以改变的。 placeholder 中数据的维度信息<code>shape</code>可以根据提供的数据推导得出，所以不一定要给出；或者对于不确定的维度，填入<code>None</code>即可。<br>这里输入<code>a</code>和<code>b</code>定义为常量，这里将它们定义为一个<code>tf.placeholder()</code>，在运行会话时需要通过<code>sess.run()</code>函数的<code>feed_dict</code>来提供<code>a</code>和<code>b</code>的取值。<code>feed_dict</code>是一个字典<code>dict</code>，在字典中需要给出每个用到的<code>placeholder</code>的取值。</p><h2 id="2-Varibale变量">2.Varibale变量</h2><ul><li><code>tf.Variable()</code>创建变量</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tf.Variable(initial_value,</span><br><span class="line">             trainable=<span class="literal">True</span>, </span><br><span class="line">             collections=<span class="literal">None</span>, </span><br><span class="line">             validate_shape=<span class="literal">True</span>, </span><br><span class="line">             name=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><table><thead><tr><th>参数名称</th><th>参数类型</th><th>含义</th></tr></thead><tbody><tr><td>initial_value</td><td>所有可以转换为Tensor的类型</td><td>变量的初始值,一般是随机生成函数的值</td></tr><tr><td>trainable</td><td>bool</td><td>是否加入到<code>GraphKeys.TRAINABLE_VARIABLES</code>被迭代优化</td></tr><tr><td>collections</td><td>list</td><td>指定该图变量的类型、默认为<code>GraphKeys.GLOBAL_VARIABLES</code></td></tr><tr><td>validate_shape</td><td>bool</td><td>是否进行类型和维度检查</td></tr><tr><td>name</td><td>string</td><td>变量的名称，如果没有指定则系统会自动分配一个唯一的值</td></tr></tbody></table><ul><li>在<code>sess</code>对变量运算前初始化所有变量</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  sess.run(init)</span><br></pre></td></tr></table></figure><ul><li>管理变量的变量空间</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">"one"</span>) :</span><br><span class="line">a = tf.get_variable (<span class="string">"a"</span>,shape=[<span class="number">1</span>],initializer=tf.constant_initializer(<span class="number">1.0</span>))</span><br></pre></td></tr></table></figure><ul><li>以上代码在名为<code>one</code>的变量空间内创建名字为<code>a</code>的变量;</li><li>因为<code>tf.variable_scope(&quot;one&quot;)</code>的参数默认<code>reuse=False</code>,所以在<code>one</code>这个变量空间内不能在创建名字为<code>a</code>的变量；</li><li>若<code>reuse=True</code>则<code>get_variable()</code>函数会直接获取<code>name</code>属性相同的己经创建的变量,获取的变量没创建过则会报错（区别于指定initializer时为创建新变量）</li></ul>]]></content>
      
      
      <categories>
          
          <category> tensorflow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tensorflow入门笔记2:计算图、张量、会话session</title>
      <link href="/2019/10/06/tensorflow-ru-men-bi-ji-2-ji-suan-tu-zhang-liang-hui-hua-session/"/>
      <url>/2019/10/06/tensorflow-ru-men-bi-ji-2-ji-suan-tu-zhang-liang-hui-hua-session/</url>
      
        <content type="html"><![CDATA[<h2 id="1-计算图">1.计算图</h2><ul><li>用户不定义计算图时，系统会自动维护一个默认的计算图,tensorflow 会自动将定义的所有计算添加到默认的计算图</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.get_default_graph() <span class="comment"># 获取当前的默认图</span></span><br></pre></td></tr></table></figure><ul><li>用户自己创建计算图，用<code>with</code>创建图指定为默认计算图后,下面的运算都在这个计算图内，变量为该计算图独有，不与其他计算图共享</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">g1 = tf.Graph()</span><br><span class="line"><span class="keyword">with</span> g1.as_default() :</span><br><span class="line">  a=tf.get_variable(<span class="string">"a"</span>,[<span class="number">2</span>],initializer=tf.ones_initializer())</span><br><span class="line">  b=tf.get_variable(<span class="string">"b"</span>,[<span class="number">2</span>],initializer=tf.zeros_initializer())</span><br></pre></td></tr></table></figure><ul><li>获取某个变量的计算图，如变量<code>a</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a.graph()</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="2-张量">2.张量</h2><ul><li>张量只是引用了程序中的运算结果而不是一个真正的数组，张量保存的是运算结果的属性，而不是真正的数字</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf </span><br><span class="line">a=tf.constant([<span class="number">1.0</span>,<span class="number">2.0</span>],name =<span class="string">"a"</span>) </span><br><span class="line">b=tf.constant([<span class="number">3.0</span>,<span class="number">4.0</span>],name =<span class="string">"b"</span>) </span><br><span class="line">result=a+b </span><br><span class="line">print(result) </span><br><span class="line">＃输出 Tensor (<span class="string">"add:0"</span>，shape=(<span class="number">2</span>,), dtype=float32)</span><br></pre></td></tr></table></figure><p><code>add:0 </code>:由加法得来的第一个输出<br><code>shape=(2,)</code>:形状为2的数组，只有一个维度，注意不是2*1，<br><code>dtype=float32</code>:元素类型为<code>float32</code></p><p>要想获得<code>result</code>的真值需定义会话<code>sess</code>进行真正的运算<br>使用<code>sess.run(result)</code><br>或<code>result.eval(session=sess)</code><br>或<code>sess</code>为默认会话时<code>result.eval()</code></p><h2 id="3-会话-Session">3.会话(Session)</h2><ul><li>定义会话</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 接上</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess :</span><br><span class="line">  tf.initialize_all_variables() </span><br><span class="line">  print(sess.run(result))</span><br><span class="line"></span><br><span class="line">＃输出［ <span class="number">4.</span> <span class="number">6.</span>]</span><br></pre></td></tr></table></figure><ul><li>指定sess为默认会话</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sess = tf.Session()</span><br><span class="line"><span class="keyword">with</span> sess.<span class="keyword">as</span> default():</span><br><span class="line">  &lt;<span class="keyword">with</span>-block&gt;</span><br></pre></td></tr></table></figure><p>在定义计算时tensorflow会自动生成一个默认的计算图，如果没有特殊指定，定义的运算会自动加入这个计算图中。通过手动指定，会话也可以成为默认的(tensorflow不会自动生成默认的会话)</p>]]></content>
      
      
      <categories>
          
          <category> tensorflow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ubuntu常用命令</title>
      <link href="/2019/09/16/ubuntu-chang-yong-ming-ling/"/>
      <url>/2019/09/16/ubuntu-chang-yong-ming-ling/</url>
      
        <content type="html"><![CDATA[<h2 id="备份、更换、更新软件源">备份、更换、更新软件源</h2><p>备份软件源</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo cp /etc/apt/sources.list /etc/apt/sources.list.backup</span><br></pre></td></tr></table></figure><a id="more"></a><p>修改文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /etc/apt/sources.list</span><br></pre></td></tr></table></figure><p>国内主要软件源</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># Ubuntu 官方源  </span></span><br><span class="line">deb http://archive.ubuntu.com/ubuntu/ gutsy main restricted universe multiverse</span><br><span class="line">deb http://archive.ubuntu.com/ubuntu/ gutsy-security main restricted universe multiverse</span><br><span class="line">deb http://archive.ubuntu.com/ubuntu/ gutsy-updates main restricted universe multiverse</span><br><span class="line">deb http://archive.ubuntu.com/ubuntu/ gutsy-proposed main restricted universe multiverse</span><br><span class="line">deb http://archive.ubuntu.com/ubuntu/ gutsy-backports main restricted universe multiverse</span><br><span class="line">deb-src http://archive.ubuntu.com/ubuntu/ gutsy main restricted universe multiverse</span><br><span class="line">deb-src http://archive.ubuntu.com/ubuntu/ gutsy-security main restricted universe multiverse</span><br><span class="line">deb-src http://archive.ubuntu.com/ubuntu/ gutsy-updates main restricted universe multiverse</span><br><span class="line">deb-src http://archive.ubuntu.com/ubuntu/ gutsy-proposed main restricted universe multiverse</span><br><span class="line">deb-src http://archive.ubuntu.com/ubuntu/ gutsy-backports main restricted universe multiverse</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#网易163</span></span><br><span class="line">deb http://mirrors.163.com/ubuntu/ trusty main restricted universe multiverse</span><br><span class="line">deb http://mirrors.163.com/ubuntu/ trusty-security main restricted universe multiverse</span><br><span class="line">deb http://mirrors.163.com/ubuntu/ trusty-updates main restricted universe multiverse</span><br><span class="line">deb http://mirrors.163.com/ubuntu/ trusty-proposed main restricted universe multiverse</span><br><span class="line">deb http://mirrors.163.com/ubuntu/ trusty-backports main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.163.com/ubuntu/ trusty main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.163.com/ubuntu/ trusty-security main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.163.com/ubuntu/ trusty-updates main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.163.com/ubuntu/ trusty-proposed main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.163.com/ubuntu/ trusty-backports main restricted universe multiverse</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 阿里云</span></span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 中科大</span></span><br><span class="line">deb http://mirrors.ustc.edu.cn/ubuntu/ xenial main restricted universe multiverse</span><br><span class="line">deb http://mirrors.ustc.edu.cn/ubuntu/ xenial-security main restricted universe multiverse</span><br><span class="line">deb http://mirrors.ustc.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse</span><br><span class="line">deb http://mirrors.ustc.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse</span><br><span class="line">deb http://mirrors.ustc.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.ustc.edu.cn/ubuntu/ xenial main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.ustc.edu.cn/ubuntu/ xenial-security main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.ustc.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.ustc.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.ustc.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse</span><br></pre></td></tr></table></figure><ul><li>更新软件源</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br></pre></td></tr></table></figure><h2 id="设置环境变量">设置环境变量</h2><p>[bash]修改单用户环境变量文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vi ~/.bashrc</span><br></pre></td></tr></table></figure><p>[bash]修改所有用户环境变量文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /etc/profile</span><br></pre></td></tr></table></figure><h2 id="root权限和用户权限切换">root权限和用户权限切换</h2><p>切换至root权限</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo su</span><br></pre></td></tr></table></figure><p>切换至用户权限</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">su &lt;username&gt;</span><br></pre></td></tr></table></figure><p>修改当前账号(root或普通用户)的密码</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">passwd</span><br></pre></td></tr></table></figure><p>修改指定用户密码</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">passwd &lt;username&gt;</span><br></pre></td></tr></table></figure><h2 id="服务器文件传输">服务器文件传输</h2><p>本地向服务器文件传输</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r &lt;uesrname&gt;@&lt;服务器ip&gt;：&lt;服务器指定文件夹路径&gt; &lt;本地所存文件路径&gt;</span><br></pre></td></tr></table></figure><p>服务器文件下载到本地</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r  &lt;本地所存文件路径&gt;  &lt;uesrname&gt;@&lt;服务器ip&gt;：&lt;服务器指定文件夹路径&gt;</span><br></pre></td></tr></table></figure><h2 id="ssh服务">ssh服务</h2><p>安装ssh</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install openssh-server</span><br></pre></td></tr></table></figure><p>启动ssh服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service sshd start</span><br></pre></td></tr></table></figure><p>查看ssh服务是否开启</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -e | grep ssh</span><br></pre></td></tr></table></figure><p>通过ssh远程访问服务器</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh &lt;username&gt;@&lt;ip&gt;</span><br></pre></td></tr></table></figure><h2 id="查看系统信息">查看系统信息</h2><p>查看系统版本信息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uname -a</span><br></pre></td></tr></table></figure><p>修改主机名</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/hostname</span><br></pre></td></tr></table></figure><p>查看英伟达GPU型号</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lspci | grep -i nvidia</span><br></pre></td></tr></table></figure><p>查看NVIDIA驱动版本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo dpkg --list | grep nvidia-*</span><br></pre></td></tr></table></figure><h2 id="Python安装及包管理">Python安装及包管理</h2><p>为python3安装pip</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install python3-pip</span><br></pre></td></tr></table></figure><p>查看python及其第三方库路径</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python <span class="comment">#python3</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.sys.path</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tensorflow入门笔记1:指定GPU及分配显存</title>
      <link href="/2019/09/16/tensorflow-ru-men-bi-ji-1-zhi-ding-gpu-ji-fen-pei-xian-cun/"/>
      <url>/2019/09/16/tensorflow-ru-men-bi-ji-1-zhi-ding-gpu-ji-fen-pei-xian-cun/</url>
      
        <content type="html"><![CDATA[<h4 id="前提">前提</h4><h4 id="1-安装好tensorflow的gpu版本及其对应CUDA">1.安装好tensorflow的gpu版本及其对应CUDA</h4><h4 id="2-有GPU">2.有GPU</h4><a id="more"></a><h2 id="1-指定某一块或多块gpu运行">1.指定某一块或多块gpu运行</h2><h3 id="方法一">方法一</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 指定第二块gpu</span></span><br><span class="line">CUDA_VISIBLE_DEVICES=1 python &#123;xxx&#125;.py</span><br></pre></td></tr></table></figure><h3 id="方法二">方法二</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> CUDA_VISIBLE_DEVICES=1</span><br><span class="line">python &#123;xxx&#125;.py</span><br></pre></td></tr></table></figure><h3 id="方法三">方法三</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"2"</span></span><br></pre></td></tr></table></figure><p>参数参考：</p><table><thead><tr><th style="text-align:left">Environment Variable Syntax</th><th style="text-align:left">Results</th></tr></thead><tbody><tr><td style="text-align:left">CUDA_VISIBLE_DEVICES=1</td><td style="text-align:left">Only device 1 will be seen</td></tr><tr><td style="text-align:left">CUDA_VISIBLE_DEVICES=0,1</td><td style="text-align:left">Devices 0 and 1 will be visible</td></tr><tr><td style="text-align:left">CUDA_VISIBLE_DEVICES=“0,1”</td><td style="text-align:left">Same as above, quotation marks are optional</td></tr><tr><td style="text-align:left">CUDA_VISIBLE_DEVICES=0,2,3</td><td style="text-align:left">Devices 0, 2, 3 will be visible; device 1 is masked</td></tr><tr><td style="text-align:left">CUDA_VISIBLE_DEVICES=&quot;&quot;</td><td style="text-align:left">No GPU will be visible</td></tr></tbody></table><h2 id="2-配置gpu显存使用率">2.配置gpu显存使用率</h2><h3 id="方法一：通过配置Session的运行参数配置gpu的使用">方法一：通过配置Session的运行参数配置gpu的使用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过配置Session的运行参数配置gpu的使用</span></span><br><span class="line"></span><br><span class="line">config = tf.ConfigProto(allow_soft_placement=<span class="literal">True</span>, allow_soft_placement=<span class="literal">True</span>)</span><br><span class="line">config.gpu_options.per_process_gpu_memory_fraction = <span class="number">0.4</span>  <span class="comment">#占用40%显存</span></span><br><span class="line">sess = tf.Session(config=config）</span><br></pre></td></tr></table></figure><p>参数参考：</p><table><thead><tr><th>Syntax</th><th style="text-align:left">Results</th></tr></thead><tbody><tr><td>tf.ConfigProto(log_device_placement=True)</td><td style="text-align:left">记录设备指派情况</td></tr><tr><td>tf.ConfigProto(allow_soft_placement=True）</td><td style="text-align:left">自动选择一个运行备</td></tr><tr><td>config.gpu_options.allow_growth = True</td><td style="text-align:left">动态申请显存</td></tr><tr><td>config.gpu_options.per_process_gpu_memory_fraction = 0.4</td><td style="text-align:left">限制GPU使用率</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> tensorflow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
