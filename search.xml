<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>pytorch训练保存检验模型基本流程</title>
      <link href="/2020/04/10/pytorch-xun-lian-bao-cun-jian-yan-mo-xing-ji-ben-liu-cheng/"/>
      <url>/2020/04/10/pytorch-xun-lian-bao-cun-jian-yan-mo-xing-ji-ben-liu-cheng/</url>
      
        <content type="html"><![CDATA[<blockquote><p>参考：<br><a href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py" target="_blank" rel="noopener">https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py</a></p></blockquote><h2 id="Step1准备数据输入">Step1准备数据输入</h2><p>按需制作训练集</p><a id="more"></a><h2 id="Step2-设计神经网络">Step2 设计神经网络</h2><p>注意forward()函数是override method，名字不能改</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.pool(F.relu(self.conv1(x)))</span><br><span class="line">        x = self.pool(F.relu(self.conv2(x)))</span><br><span class="line">        x = x.view(<span class="number">-1</span>, <span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>)</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = Net()</span><br></pre></td></tr></table></figure><p>##Step3 定义损失函数和优化方法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure><p>##Step4 训练网络</p><p>####4.1 循环更新参数</p><ul><li>for epoch in range(times):<ul><li>参数的梯度置零</li><li>前向传播获取神经网络的输出</li><li>比较输出与标签的差距并计算损失</li><li>损失反向传播</li><li>优化器更新参数</li><li>累计损失</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">2</span>):  <span class="comment"># loop over the dataset multiple times</span></span><br><span class="line"></span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> enumerate(trainloader, <span class="number">0</span>):</span><br><span class="line">        <span class="comment"># get the inputs; data is a list of [inputs, labels]</span></span><br><span class="line">        inputs, labels = data</span><br><span class="line"></span><br><span class="line">        <span class="comment"># zero the parameter gradients</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># forward + backward + optimize</span></span><br><span class="line">        outputs = net(inputs)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        running_loss += loss.item()</span><br></pre></td></tr></table></figure><p>##Step4 保存训练结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.save(net.state_dict(), PATH)</span><br></pre></td></tr></table></figure><h2 id="Step5-恢复并评估模型">Step5 恢复并评估模型</h2><p>####5.1恢复模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net = Net()</span><br><span class="line">net.load_state_dict(torch.load(PATH))</span><br></pre></td></tr></table></figure><p>####5.2 测试集前向传播得到输出</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">  outputs = net(images)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VNC访问mate或gnome桌面的服务端配置</title>
      <link href="/2020/04/10/vnc-fang-wen-mate-huo-gnome-zhuo-mian-de-fu-wu-duan-pei-zhi/"/>
      <url>/2020/04/10/vnc-fang-wen-mate-huo-gnome-zhuo-mian-de-fu-wu-duan-pei-zhi/</url>
      
        <content type="html"><![CDATA[<h2 id="VNCserver">VNCserver</h2><ul><li><h4 id="安装vnc4server">安装vnc4server</h4></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install vnc4server</span><br></pre></td></tr></table></figure><ul><li><h4 id="启动vncserver-指定为端口1为例">启动vncserver(指定为端口1为例)</h4></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vncserver :1</span><br></pre></td></tr></table></figure><blockquote><p>第一次启动vncserver会自动在<code>~/.vnc/</code>目录下生成<code>~/.vnc/xstartup</code>等文件</p></blockquote><ul><li><h4 id="然后关闭vncserver">然后关闭vncserver</h4></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vncserver -kill :1</span><br></pre></td></tr></table></figure><a id="more"></a><ul><li><h4 id="按附录代码修改xstartup文件">按附录代码修改xstartup文件</h4><ul><li>方法一</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.vnc/xstartup</span><br></pre></td></tr></table></figure><ul><li>方法二</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rm ~/.vnc/xstartup # 删除掉xstartup文件</span><br><span class="line">vi ~/.vnc/xstartup # 创建新的xstartup文件直接粘贴附录代码</span><br><span class="line">chmod 777 ~/.vnc/xstartup # 授权使其可执行</span><br></pre></td></tr></table></figure></li></ul><h2 id="附录">附录</h2><h4 id="gnome桌面">gnome桌面</h4><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/<span class="keyword">sh</span></span><br><span class="line"></span><br><span class="line"># Uncomment the following two lines <span class="keyword">for</span> <span class="keyword">normal</span> desktop:</span><br><span class="line"># unset SESSION_MANAGER</span><br><span class="line"># exec /etc/X11/xinit/xinitrc</span><br><span class="line">  </span><br><span class="line">[ -<span class="keyword">x</span> /etc/vnc/xstartup ] &amp;&amp; exec /etc/vnc/xstartup</span><br><span class="line">[ -r $HOME/.Xresources ] &amp;&amp; xrdb $HOME/.Xresources</span><br><span class="line">xsetroot -solid grey </span><br><span class="line">vncconfig -iconic &amp;</span><br><span class="line"><span class="keyword">x</span>-terminal-emulator -geometry <span class="number">80</span>x24+<span class="number">10</span>+<span class="number">10</span> -<span class="keyword">ls</span> -title <span class="string">"$VNCDESKTOP Desktop"</span> &amp;</span><br><span class="line"><span class="keyword">x</span>-window-manager &amp;</span><br><span class="line"></span><br><span class="line">gnome-panel &amp;</span><br><span class="line">gnome-settings-daemon &amp;</span><br><span class="line">metacity &amp;</span><br></pre></td></tr></table></figure><h4 id="mate桌面">mate桌面</h4><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/<span class="keyword">sh</span></span><br><span class="line"># Uncomment the following two lines <span class="keyword">for</span> <span class="keyword">normal</span> desktop:</span><br><span class="line"># unset SESSION_MANAGER</span><br><span class="line"># exec /etc/X11/xinit/xinitrc</span><br><span class="line"></span><br><span class="line">#export XKL_XMODMAP_DISABLE=<span class="number">1</span></span><br><span class="line">unset SESSION_MANAGER</span><br><span class="line">unset DBUS_SESSION_BUS_ADDRESS</span><br><span class="line">[ -<span class="keyword">x</span> /etc/vnc/xstartup ] &amp;&amp; exec /etc/vnc/xstartup</span><br><span class="line">[ -r $HOME/.Xresources ] &amp;&amp; xrdb $HOME/.Xresources</span><br><span class="line">xsetroot -solid grey</span><br><span class="line">vncconfig -iconic &amp;</span><br><span class="line"># <span class="keyword">x</span>-terminal-emulator -geometry <span class="number">80</span>x24+<span class="number">10</span>+<span class="number">10</span> -<span class="keyword">ls</span> -title <span class="string">"$VNCDESKTOP Desktop"</span> &amp;</span><br><span class="line">mate-session &amp;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tensorflow训练保存检验模型基本流程</title>
      <link href="/2020/04/10/tensorflow-xun-lian-bao-cun-jian-yan-mo-xing-ji-ben-liu-cheng/"/>
      <url>/2020/04/10/tensorflow-xun-lian-bao-cun-jian-yan-mo-xing-ji-ben-liu-cheng/</url>
      
        <content type="html"><![CDATA[<p>参考：<br>TensorFlow运作方式入门http://www.tensorfly.cn/tfdoc/tutorials/mnist_tf.html</p><p>注意以下代码仅为示例</p><h2 id="Step1准备数据输入">Step1准备数据输入</h2><p>按需制作训练集</p><h2 id="Step2-构造图表-Build-the-Graph">Step2 构造图表(Build the Graph)</h2><p>####2.1定义占位符</p><p>在创建session的时候数据才真正流入神经网络</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">images_placeholder = tf.placeholder(tf.float32, shape=(batch_size,</span><br><span class="line">                                                       IMAGE_PIXELS))</span><br><span class="line">labels_placeholder = tf.placeholder(tf.int32, shape=(batch_size))</span><br></pre></td></tr></table></figure><a id="more"></a><p>####2.2构造inference()<br>占位符为输入，使数据经过神经网络向前反馈输出预测结果<br>每一层都创建于一个唯一的<a href="http://www.tensorfly.cn/tfdoc/api_docs/python/framework.html#name_scope" target="_blank" rel="noopener"><code>tf.name_scope</code></a>之下，创建于该作用域之下的所有元素都将带有其前缀</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inference</span><span class="params">(images, hidden1_units, hidden2_units)</span>:</span></span><br><span class="line">  <span class="comment"># Hidden 1</span></span><br><span class="line">  <span class="keyword">with</span> tf.name_scope(<span class="string">'hidden1'</span>):</span><br><span class="line">    weights = tf.Variable(</span><br><span class="line">        tf.truncated_normal([IMAGE_PIXELS, hidden1_units],</span><br><span class="line">                            stddev=<span class="number">1.0</span> / math.sqrt(float(IMAGE_PIXELS))),</span><br><span class="line">        name=<span class="string">'weights'</span>)</span><br><span class="line">    biases = tf.Variable(tf.zeros([hidden1_units]),</span><br><span class="line">                         name=<span class="string">'biases'</span>)</span><br><span class="line">    hidden1 = tf.nn.relu(tf.matmul(images, weights) + biases)</span><br><span class="line">  <span class="comment"># Hidden 2</span></span><br><span class="line">  <span class="keyword">with</span> tf.name_scope(<span class="string">'hidden2'</span>):</span><br><span class="line">    weights = tf.Variable(</span><br><span class="line">        tf.truncated_normal([hidden1_units, hidden2_units],</span><br><span class="line">                            stddev=<span class="number">1.0</span> / math.sqrt(float(hidden1_units))),</span><br><span class="line">        name=<span class="string">'weights'</span>)</span><br><span class="line">    biases = tf.Variable(tf.zeros([hidden2_units]),</span><br><span class="line">                         name=<span class="string">'biases'</span>)</span><br><span class="line">    hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases)</span><br><span class="line">  <span class="comment"># Linear</span></span><br><span class="line">  <span class="keyword">with</span> tf.name_scope(<span class="string">'softmax_linear'</span>):</span><br><span class="line">    weights = tf.Variable(</span><br><span class="line">        tf.truncated_normal([hidden2_units, NUM_CLASSES],</span><br><span class="line">                            stddev=<span class="number">1.0</span> / math.sqrt(float(hidden2_units))),</span><br><span class="line">        name=<span class="string">'weights'</span>)</span><br><span class="line">    biases = tf.Variable(tf.zeros([NUM_CLASSES]),</span><br><span class="line">                         name=<span class="string">'biases'</span>)</span><br><span class="line">    logits = tf.matmul(hidden2, weights) + biases</span><br><span class="line">  <span class="keyword">return</span> logits</span><br></pre></td></tr></table></figure><p>####2.3损失(Loss)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits,</span><br><span class="line">                                                        onehot_labels,</span><br><span class="line">                                                        name=<span class="string">'entropy'</span>)</span><br><span class="line">loss = tf.reduce_mean(cross_entropy, name=<span class="string">'entropy_mean'</span>)</span><br></pre></td></tr></table></figure><p>####2.4训练(training)<br>#####2.4.1将损失最小化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate)</span><br><span class="line">train_op = optimizer.minimize(loss, global_step=global_step)</span><br></pre></td></tr></table></figure><p>#####2.4.2生成一个变量用于保存全局训练步骤（global training step）的数值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">global_step = tf.Variable(<span class="number">0</span>, name=<span class="string">'global_step'</span>, trainable=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p>##step3 启动会话并执行图表</p><p>####3.1关联图表构建会话</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">saver = tf.train.Saver() <span class="comment">#保存模型：定义一个saver</span></span><br><span class="line"><span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        init = tf.initialize_all_variables()</span><br><span class="line">        sess.run(init)</span><br></pre></td></tr></table></figure><p>####3.2 feed_dict参数传入sess.run()，真正训练模型，保存模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> xrange(FLAGS.max_steps):</span><br><span class="line">    feed_dict = &#123;</span><br><span class="line">        images_placeholder: images_feed,</span><br><span class="line">        labels_placeholder: labels_feed,</span><br><span class="line">    &#125;</span><br><span class="line">    _, loss_value = sess.run([train_op, loss],</span><br><span class="line">                     feed_dict=feed_dict)</span><br><span class="line">    </span><br><span class="line">    saver.save(sess, FLAGS.train_dir, global_step=step)</span><br><span class="line">    <span class="comment">#保存模型：检查点保存到FLAGS.train_dir,</span></span><br></pre></td></tr></table></figure><h2 id="Step4-恢复并评估模型">Step4 恢复并评估模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    model_dir=tf.train.latest_checkpoint(<span class="string">'ckpt/'</span>)</span><br><span class="line">    saver.restore(sess,model_dir)</span><br><span class="line">    ***=sess.run(***, feed_dict=&#123;))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> tensorflow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tensorflow入门笔记3:placeholder机制和Variable变量</title>
      <link href="/2019/10/06/tensorflow-ru-men-bi-ji-3-placeholder-ji-zhi-he-variable-bian-liang/"/>
      <url>/2019/10/06/tensorflow-ru-men-bi-ji-3-placeholder-ji-zhi-he-variable-bian-liang/</url>
      
        <content type="html"><![CDATA[<h2 id="1-placeholder-机制">1.placeholder 机制</h2><ul><li>placeholder 机制的作用</li></ul><p>网络的输入数据是一个矩阵，我们把多个这样的矩阵数据打包成一个很大的数据集，如果将这个数据集当作变量或常量一下子输入到网络中，那么就需要定义很多的网络输入常量，于是计算图上将会涌现大量的输入节点。这是不利的，这些节点的利用率很低。<br>placehoder 机制被设计用来解决这个问题。编程时只需要将数据通过 placeholder 传入 TensorFlow 计算图即可。</p><ul><li>使用 <code>tf.placeholder()</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">a = tf.placeholder(tf.float32,shape=(<span class="number">2</span>),name=<span class="string">"input"</span>) </span><br><span class="line">b = tf.placeholder(tf.float32,shape=(<span class="number">2</span>),name=<span class="string">"input"</span>)</span><br><span class="line">result = a+b</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess :</span><br><span class="line">  sess.run(result,feed_dict=&#123;a:[<span class="number">1.0</span>,<span class="number">2.0</span>],b:[<span class="number">3.0</span>,<span class="number">4.0</span>]&#125;)</span><br><span class="line">  print(result)</span><br><span class="line">  ＃输出[<span class="number">4.</span>,<span class="number">6.</span>]</span><br></pre></td></tr></table></figure><a id="more"></a><p>在 placeholder 定义时，这个位置上的数据类型<code>dtype</code>是需要指定且不可以改变的。 placeholder 中数据的维度信息<code>shape</code>可以根据提供的数据推导得出，所以不一定要给出；或者对于不确定的维度，填入<code>None</code>即可。<br>这里输入<code>a</code>和<code>b</code>定义为常量，这里将它们定义为一个<code>tf.placeholder()</code>，在运行会话时需要通过<code>sess.run()</code>函数的<code>feed_dict</code>来提供<code>a</code>和<code>b</code>的取值。<code>feed_dict</code>是一个字典<code>dict</code>，在字典中需要给出每个用到的<code>placeholder</code>的取值。</p><h2 id="2-Varibale变量">2.Varibale变量</h2><ul><li><code>tf.Variable()</code>创建变量</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tf.Variable(initial_value,</span><br><span class="line">             trainable=<span class="literal">True</span>, </span><br><span class="line">             collections=<span class="literal">None</span>, </span><br><span class="line">             validate_shape=<span class="literal">True</span>, </span><br><span class="line">             name=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><table><thead><tr><th>参数名称</th><th>参数类型</th><th>含义</th></tr></thead><tbody><tr><td>initial_value</td><td>所有可以转换为Tensor的类型</td><td>变量的初始值,一般是随机生成函数的值</td></tr><tr><td>trainable</td><td>bool</td><td>是否加入到<code>GraphKeys.TRAINABLE_VARIABLES</code>被迭代优化</td></tr><tr><td>collections</td><td>list</td><td>指定该图变量的类型、默认为<code>GraphKeys.GLOBAL_VARIABLES</code></td></tr><tr><td>validate_shape</td><td>bool</td><td>是否进行类型和维度检查</td></tr><tr><td>name</td><td>string</td><td>变量的名称，如果没有指定则系统会自动分配一个唯一的值</td></tr></tbody></table><ul><li>在<code>sess</code>对变量运算前初始化所有变量</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  sess.run(init)</span><br></pre></td></tr></table></figure><ul><li>管理变量的变量空间</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">"one"</span>) :</span><br><span class="line">a = tf.get_variable (<span class="string">"a"</span>,shape=[<span class="number">1</span>],initializer=tf.constant_initializer(<span class="number">1.0</span>))</span><br></pre></td></tr></table></figure><ul><li>以上代码在名为<code>one</code>的变量空间内创建名字为<code>a</code>的变量;</li><li>因为<code>tf.variable_scope(&quot;one&quot;)</code>的参数默认<code>reuse=False</code>,所以在<code>one</code>这个变量空间内不能在创建名字为<code>a</code>的变量；</li><li>若<code>reuse=True</code>则<code>get_variable()</code>函数会直接获取<code>name</code>属性相同的己经创建的变量,获取的变量没创建过则会报错（区别于指定initializer时为创建新变量）</li></ul>]]></content>
      
      
      <categories>
          
          <category> tensorflow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tensorflow入门笔记2:计算图、张量、会话session</title>
      <link href="/2019/10/06/tensorflow-ru-men-bi-ji-2-ji-suan-tu-zhang-liang-hui-hua-session/"/>
      <url>/2019/10/06/tensorflow-ru-men-bi-ji-2-ji-suan-tu-zhang-liang-hui-hua-session/</url>
      
        <content type="html"><![CDATA[<h2 id="1-计算图">1.计算图</h2><ul><li>用户不定义计算图时，系统会自动维护一个默认的计算图,tensorflow 会自动将定义的所有计算添加到默认的计算图</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.get_default_graph() <span class="comment"># 获取当前的默认图</span></span><br></pre></td></tr></table></figure><ul><li>用户自己创建计算图，用<code>with</code>创建图指定为默认计算图后,下面的运算都在这个计算图内，变量为该计算图独有，不与其他计算图共享</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">g1 = tf.Graph()</span><br><span class="line"><span class="keyword">with</span> g1.as_default() :</span><br><span class="line">  a=tf.get_variable(<span class="string">"a"</span>,[<span class="number">2</span>],initializer=tf.ones_initializer())</span><br><span class="line">  b=tf.get_variable(<span class="string">"b"</span>,[<span class="number">2</span>],initializer=tf.zeros_initializer())</span><br></pre></td></tr></table></figure><ul><li>获取某个变量的计算图，如变量<code>a</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a.graph()</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="2-张量">2.张量</h2><ul><li>张量只是引用了程序中的运算结果而不是一个真正的数组，张量保存的是运算结果的属性，而不是真正的数字</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf </span><br><span class="line">a=tf.constant([<span class="number">1.0</span>,<span class="number">2.0</span>],name =<span class="string">"a"</span>) </span><br><span class="line">b=tf.constant([<span class="number">3.0</span>,<span class="number">4.0</span>],name =<span class="string">"b"</span>) </span><br><span class="line">result=a+b </span><br><span class="line">print(result) </span><br><span class="line">＃输出 Tensor (<span class="string">"add:0"</span>，shape=(<span class="number">2</span>,), dtype=float32)</span><br></pre></td></tr></table></figure><p><code>add:0 </code>:由加法得来的第一个输出<br><code>shape=(2,)</code>:形状为2的数组，只有一个维度，注意不是2*1，<br><code>dtype=float32</code>:元素类型为<code>float32</code></p><p>要想获得<code>result</code>的真值需定义会话<code>sess</code>进行真正的运算<br>使用<code>sess.run(result)</code><br>或<code>result.eval(session=sess)</code><br>或<code>sess</code>为默认会话时<code>result.eval()</code></p><h2 id="3-会话-Session">3.会话(Session)</h2><ul><li>定义会话</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 接上</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess :</span><br><span class="line">  tf.initialize_all_variables() </span><br><span class="line">  print(sess.run(result))</span><br><span class="line"></span><br><span class="line">＃输出［ <span class="number">4.</span> <span class="number">6.</span>]</span><br></pre></td></tr></table></figure><ul><li>指定sess为默认会话</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sess = tf.Session()</span><br><span class="line"><span class="keyword">with</span> sess.<span class="keyword">as</span> default():</span><br><span class="line">  &lt;<span class="keyword">with</span>-block&gt;</span><br></pre></td></tr></table></figure><p>在定义计算时tensorflow会自动生成一个默认的计算图，如果没有特殊指定，定义的运算会自动加入这个计算图中。通过手动指定，会话也可以成为默认的(tensorflow不会自动生成默认的会话)</p>]]></content>
      
      
      <categories>
          
          <category> tensorflow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ubuntu常用命令</title>
      <link href="/2019/09/16/ubuntu-chang-yong-ming-ling/"/>
      <url>/2019/09/16/ubuntu-chang-yong-ming-ling/</url>
      
        <content type="html"><![CDATA[<h2 id="备份、更换、更新软件源">备份、更换、更新软件源</h2><p>备份软件源</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo cp /etc/apt/sources.list /etc/apt/sources.list.backup</span><br></pre></td></tr></table></figure><a id="more"></a><p>修改文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /etc/apt/sources.list</span><br></pre></td></tr></table></figure><p>国内主要软件源</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># Ubuntu 官方源  </span></span><br><span class="line">deb http://archive.ubuntu.com/ubuntu/ gutsy main restricted universe multiverse</span><br><span class="line">deb http://archive.ubuntu.com/ubuntu/ gutsy-security main restricted universe multiverse</span><br><span class="line">deb http://archive.ubuntu.com/ubuntu/ gutsy-updates main restricted universe multiverse</span><br><span class="line">deb http://archive.ubuntu.com/ubuntu/ gutsy-proposed main restricted universe multiverse</span><br><span class="line">deb http://archive.ubuntu.com/ubuntu/ gutsy-backports main restricted universe multiverse</span><br><span class="line">deb-src http://archive.ubuntu.com/ubuntu/ gutsy main restricted universe multiverse</span><br><span class="line">deb-src http://archive.ubuntu.com/ubuntu/ gutsy-security main restricted universe multiverse</span><br><span class="line">deb-src http://archive.ubuntu.com/ubuntu/ gutsy-updates main restricted universe multiverse</span><br><span class="line">deb-src http://archive.ubuntu.com/ubuntu/ gutsy-proposed main restricted universe multiverse</span><br><span class="line">deb-src http://archive.ubuntu.com/ubuntu/ gutsy-backports main restricted universe multiverse</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#网易163</span></span><br><span class="line">deb http://mirrors.163.com/ubuntu/ trusty main restricted universe multiverse</span><br><span class="line">deb http://mirrors.163.com/ubuntu/ trusty-security main restricted universe multiverse</span><br><span class="line">deb http://mirrors.163.com/ubuntu/ trusty-updates main restricted universe multiverse</span><br><span class="line">deb http://mirrors.163.com/ubuntu/ trusty-proposed main restricted universe multiverse</span><br><span class="line">deb http://mirrors.163.com/ubuntu/ trusty-backports main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.163.com/ubuntu/ trusty main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.163.com/ubuntu/ trusty-security main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.163.com/ubuntu/ trusty-updates main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.163.com/ubuntu/ trusty-proposed main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.163.com/ubuntu/ trusty-backports main restricted universe multiverse</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 阿里云</span></span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 中科大</span></span><br><span class="line">deb http://mirrors.ustc.edu.cn/ubuntu/ xenial main restricted universe multiverse</span><br><span class="line">deb http://mirrors.ustc.edu.cn/ubuntu/ xenial-security main restricted universe multiverse</span><br><span class="line">deb http://mirrors.ustc.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse</span><br><span class="line">deb http://mirrors.ustc.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse</span><br><span class="line">deb http://mirrors.ustc.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.ustc.edu.cn/ubuntu/ xenial main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.ustc.edu.cn/ubuntu/ xenial-security main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.ustc.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.ustc.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.ustc.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse</span><br></pre></td></tr></table></figure><ul><li>更新软件源</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br></pre></td></tr></table></figure><h2 id="设置环境变量">设置环境变量</h2><p>[bash]修改单用户环境变量文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vi ~/.bashrc</span><br></pre></td></tr></table></figure><p>[bash]修改所有用户环境变量文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /etc/profile</span><br></pre></td></tr></table></figure><h2 id="root权限和用户权限切换">root权限和用户权限切换</h2><p>切换至root权限</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo su</span><br></pre></td></tr></table></figure><p>切换至用户权限</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">su &lt;username&gt;</span><br></pre></td></tr></table></figure><p>修改当前账号(root或普通用户)的密码</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">passwd</span><br></pre></td></tr></table></figure><p>修改指定用户密码</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">passwd &lt;username&gt;</span><br></pre></td></tr></table></figure><h2 id="服务器文件传输">服务器文件传输</h2><p>本地向服务器文件传输</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r &lt;uesrname&gt;@&lt;服务器ip&gt;：&lt;服务器指定文件夹路径&gt; &lt;本地所存文件路径&gt;</span><br></pre></td></tr></table></figure><p>服务器文件下载到本地</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r  &lt;本地所存文件路径&gt;  &lt;uesrname&gt;@&lt;服务器ip&gt;：&lt;服务器指定文件夹路径&gt;</span><br></pre></td></tr></table></figure><h2 id="ssh服务">ssh服务</h2><p>安装ssh</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install openssh-server</span><br></pre></td></tr></table></figure><p>启动ssh服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service sshd start</span><br></pre></td></tr></table></figure><p>查看ssh服务是否开启</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -e | grep ssh</span><br></pre></td></tr></table></figure><p>通过ssh远程访问服务器</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh &lt;username&gt;@&lt;ip&gt;</span><br></pre></td></tr></table></figure><h2 id="查看系统信息">查看系统信息</h2><p>查看系统版本信息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uname -a</span><br></pre></td></tr></table></figure><p>修改主机名</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/hostname</span><br></pre></td></tr></table></figure><p>查看英伟达GPU型号</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lspci | grep -i nvidia</span><br></pre></td></tr></table></figure><p>查看NVIDIA驱动版本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo dpkg --list | grep nvidia-*</span><br></pre></td></tr></table></figure><h2 id="Python安装及包管理">Python安装及包管理</h2><p>为python3安装pip</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install python3-pip</span><br></pre></td></tr></table></figure><p>查看python及其第三方库路径</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python <span class="comment">#python3</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.sys.path</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tensorflow入门笔记1:指定GPU及分配显存</title>
      <link href="/2019/09/16/tensorflow-ru-men-bi-ji-1-zhi-ding-gpu-ji-fen-pei-xian-cun/"/>
      <url>/2019/09/16/tensorflow-ru-men-bi-ji-1-zhi-ding-gpu-ji-fen-pei-xian-cun/</url>
      
        <content type="html"><![CDATA[<h4 id="前提">前提</h4><h4 id="1-安装好tensorflow的gpu版本及其对应CUDA">1.安装好tensorflow的gpu版本及其对应CUDA</h4><h4 id="2-有GPU">2.有GPU</h4><a id="more"></a><h2 id="1-指定某一块或多块gpu运行">1.指定某一块或多块gpu运行</h2><h3 id="方法一">方法一</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 指定第二块gpu</span></span><br><span class="line">CUDA_VISIBLE_DEVICES=1 python &#123;xxx&#125;.py</span><br></pre></td></tr></table></figure><h3 id="方法二">方法二</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> CUDA_VISIBLE_DEVICES=1</span><br><span class="line">python &#123;xxx&#125;.py</span><br></pre></td></tr></table></figure><h3 id="方法三">方法三</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"2"</span></span><br></pre></td></tr></table></figure><p>参数参考：</p><table><thead><tr><th style="text-align:left">Environment Variable Syntax</th><th style="text-align:left">Results</th></tr></thead><tbody><tr><td style="text-align:left">CUDA_VISIBLE_DEVICES=1</td><td style="text-align:left">Only device 1 will be seen</td></tr><tr><td style="text-align:left">CUDA_VISIBLE_DEVICES=0,1</td><td style="text-align:left">Devices 0 and 1 will be visible</td></tr><tr><td style="text-align:left">CUDA_VISIBLE_DEVICES=“0,1”</td><td style="text-align:left">Same as above, quotation marks are optional</td></tr><tr><td style="text-align:left">CUDA_VISIBLE_DEVICES=0,2,3</td><td style="text-align:left">Devices 0, 2, 3 will be visible; device 1 is masked</td></tr><tr><td style="text-align:left">CUDA_VISIBLE_DEVICES=&quot;&quot;</td><td style="text-align:left">No GPU will be visible</td></tr></tbody></table><h2 id="2-配置gpu显存使用率">2.配置gpu显存使用率</h2><h3 id="方法一：通过配置Session的运行参数配置gpu的使用">方法一：通过配置Session的运行参数配置gpu的使用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过配置Session的运行参数配置gpu的使用</span></span><br><span class="line"></span><br><span class="line">config = tf.ConfigProto(allow_soft_placement=<span class="literal">True</span>, allow_soft_placement=<span class="literal">True</span>)</span><br><span class="line">config.gpu_options.per_process_gpu_memory_fraction = <span class="number">0.4</span>  <span class="comment">#占用40%显存</span></span><br><span class="line">sess = tf.Session(config=config）</span><br></pre></td></tr></table></figure><p>参数参考：</p><table><thead><tr><th>Syntax</th><th style="text-align:left">Results</th></tr></thead><tbody><tr><td>tf.ConfigProto(log_device_placement=True)</td><td style="text-align:left">记录设备指派情况</td></tr><tr><td>tf.ConfigProto(allow_soft_placement=True）</td><td style="text-align:left">自动选择一个运行备</td></tr><tr><td>config.gpu_options.allow_growth = True</td><td style="text-align:left">动态申请显存</td></tr><tr><td>config.gpu_options.per_process_gpu_memory_fraction = 0.4</td><td style="text-align:left">限制GPU使用率</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> tensorflow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
